import tensorflow as tf
import os
from tensorflow.keras.callbacks import ModelCheckpoint

# --- ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©Ø±Ø¯Ù† Ú©Ø¯Ù‡Ø§ÛŒ Ù‡Ù…â€ŒÚ¯Ø±ÙˆÙ‡ÛŒâ€ŒÙ‡Ø§ ---
try:
    # Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: ØªØ§Ø¨Ø¹ build_baseline_model Ø¨Ø§ÛŒØ¯ Ø§Ø² Ù†ÙØ± Ø¯ÙˆÙ… Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø´ÙˆØ¯
    from model import build_baseline_model
except ImportError:
    # Ø§Ú¯Ø± Ù‡Ù…â€ŒÚ¯Ø±ÙˆÙ‡ÛŒ Ù‡Ù†ÙˆØ² Ú©Ø¯ Ø±Ø§ Ù†Ù¾ÙˆØ´ Ù†Ú©Ø±Ø¯Ù‡ØŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù…ÙˆÙ‚Øª Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ú©Ø§Ø± ØªÙˆ Ù†Ø®ÙˆØ§Ø¨Ø¯
    print("âš ï¸ Warning: 'src/model.py' not found. Using dummy model for DevOps test.")
    from tensorflow.keras import layers, models
    def build_baseline_model():
        model = models.Sequential([
            layers.Input(shape=(224, 224, 3)),
            layers.Flatten(),
            layers.Dense(1, activation='sigmoid') # Ø®Ø±ÙˆØ¬ÛŒ Û± Ø¨Ø±Ø§ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ
        ])
        return model

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Configurations) ---
IMG_HEIGHT = 224
IMG_WIDTH = 224
BATCH_SIZE = 32
# Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: Ø¨Ø±Ø§ÛŒ Ø§Ø³Ù…ÙˆÚ© ØªØ³Øª ÙÙ‚Ø· Û± ÛŒØ§ Û² Ø§Ù¾ÙˆÚ© Ú©Ø§ÙÛŒ Ø§Ø³Øª
EPOCHS = 2 
DATA_DIR = "dataset/raw" 
MODEL_SAVE_PATH = "models/baseline_model.h5"

def main():
    print("ğŸš€ Starting Smoke Test Pipeline...")

    # 1. Ú†Ú© Ú©Ø±Ø¯Ù† GPU
    if tf.config.list_physical_devices('GPU'):
        print("âœ… GPU detected.")
    else:
        print("âš ï¸ Running on CPU.")

    # 2. Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¯ÛŒØªØ§Ù‡Ø§ (Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² image_dataset_from_directory)
    if not os.path.exists(DATA_DIR):
        print(f"âŒ Error: Dataset directory '{DATA_DIR}' not found.")
        return

    print("ğŸ“‚ Loading dataset...")
    # Ù†Ú©ØªÙ‡ ÙÙ†ÛŒ: Ú†ÙˆÙ† Ù„Ø§Ø³ ÙØ§Ù†Ú©Ø´Ù† binary_crossentropy Ø§Ø³ØªØŒ label_mode Ø¨Ø§ÛŒØ¯ 'binary' Ø¨Ø§Ø´Ø¯
    train_ds = tf.keras.utils.image_dataset_from_directory(
        DATA_DIR,
        validation_split=0.2,
        subset="training",
        seed=123,
        image_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE,
        label_mode='binary' 
    )

    val_ds = tf.keras.utils.image_dataset_from_directory(
        DATA_DIR,
        validation_split=0.2,
        subset="validation",
        seed=123,
        image_size=(IMG_HEIGHT, IMG_WIDTH),
        batch_size=BATCH_SIZE,
        label_mode='binary'
    )

    # Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: Ø§Ø¹Ù…Ø§Ù„ ØªØ§Ø¨Ø¹ preprocessing Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    # Ù†Ú©ØªÙ‡: Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ø±Ù† preprocessing Ù„Ø§ÛŒÙ‡ Ø§ÙˆÙ„ Ù…Ø¯Ù„ Ø§Ø³ØªØŒ 
    # Ø§Ù…Ø§ Ø§Ú¯Ø± ØªØ§Ø¨Ø¹ Ø¬Ø¯Ø§ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ (Rescaling) Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…:
    normalization_layer = tf.keras.layers.Rescaling(1./255)
    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))

    # 3. Ø³Ø§Ø®Øª Ùˆ Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„ Ù…Ø¯Ù„
    print("ğŸ—ï¸ Building model...")
    model = build_baseline_model()
    
    # Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„ Ø¨Ø§ adam Ùˆ binary_crossentropy
    model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # 4. Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ (Smoke Test)
    print("ğŸ”¥ Starting training (Smoke Test)...")
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=EPOCHS
    )

    # 5. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ (Ø·Ø¨Ù‚ Ø¯Ø³ØªÙˆØ± Ø¹Ú©Ø³: ÙØ±Ù…Øª .h5 Ø¯Ø± Ù¾ÙˆØ´Ù‡ models)
    if not os.path.exists('models'):
        os.makedirs('models')
    
    model.save(MODEL_SAVE_PATH)
    print(f"ğŸ’¾ Model saved successfully at {MODEL_SAVE_PATH}")

if __name__ == "__main__":
    main()
